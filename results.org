* Non-ambiguous annotations

Training the classifier on non-ambiguous annotations:

|Corpus|Number of annotations|
|EMEA|468402|
|Medline|5152543|

** Annotation counts

|N|Group|*EMEA*|Percent|*Medline*|Percent|
|1|ANAT|31531|7%|618274|12%|
|2|PHYS|25074|5%|319140|6%|
|3|DEVI|12124|3%|66772|1%|
|4|PHEN|10120|2%|113796|2%|
|5|OBJC|20440|4%|223999|4%|
|6|LIVB|65222|14%|661970|13%|
|7|CHEM|135813|29%|536262|10%|
|8|PROC|70094|15%|1162085|23%|
|9|GEOG|7101|2%|79592|2%|
|10|DISO|90883|19%|1370653|27%|
||Total|468402|100%|5152543|100%|

* Classifiers

** Error rates

Percentage of errors over the test set

|Classifier|CV folds|Error rate *EMEA*|Error rate *Medline*|
|Constant fit (theoretic)||71%|73%|
|VeryVeryNaiveBayes|10|58.7%|63.8%|
|NaiveBayesContextRestricted (window size=4)|10|47.0%|59.0%|
|NaiveBayesContextRestricted (window size=3)|10|45.0%|57.5%|
|NaiveBayesContextRestricted (window size=2)|10|43.7%|57.2%|
|NaiveBayesContextRestricted (window size=1)|10|49.0%|55.4%|
|NaiveBayesContexRestrictedBigrams(window size=2)|10|58.4%|65.8%|

Theoretic contant fit - always predict the most numerous class.

* Agreement MTurk vs. Classifier

** VeryVeryNaiveBayes

Data from Mechanical Turk was imported: annotations with agreement larger than a threshold were considered. Classifiers were trained on EMEA and Medline to predict groups of these annotations. Below are percentages of annotations for which labels predicted by MTurk and classifiers match.

|Vote agreement threshold|Total votes|Classifier trained on *EMEA*|Classifier trained on *Medline*|
|50%|170|||
|60%|169|11.8%|22.48%|
|65%|169|||
|70%|60|25.0%|25.0%|
|75%|49|30.1%|26.5%|
|99%|48|||

The result with the largest agreement was analyzed by hand, see [[http://davtyan.org/pml/mturk-vs-classifier-0.75-emea.xlsx][the annotated table]]. Subjectively, in conflicts MTurk is mostly right and the classifier is mostly wrong. The classifier should be tweaked to increase the agreement.

** NaiveBayesContextRestricted

|Vote agreement threshold|Classifier trained on *EMEA*|Classifier trained on *Medline*|Window size|
|60%|17.2%||1|
|60%|23.7%|26.0%|2|
|75%|16.3%||1|
|75%|28.6%|32.6%|2|

** OptionAwareRandom

This is to provide a baseline for agreement for classifiers which decide between possible groups only. As the variability of classifier results is very high, the agreement levels are respresented with confidence intervals retrieved by 1000 simulations each.

|Vote agreement threshold|Classifier trained on *EMEA*|Classifier trained on *Medline*|
|60%|48.6% ± 2 * 3.6%|48.6% ± 2 * 3.9%|
|75%|49.1% ± 2 * 7.2% |48.8% ± 2 * 7.1%|

** OptionAwareNaiveBayesFullContext

|Vote agreement threshold|Classifier trained on *EMEA*|Classifier trained on *Medline*|
|75%|57.1%|73.5%|

** OptionAwareLogisticRegression

|Vote agreement threshold|Classifier trained on *EMEA*|Classifier trained on *Medline*|Window size|
|75%|46.9%|61.2%|3|
|75%|46.9%||2|
|75%|46.9%||1|
|60%|46.9%||2|

** OptionAwareNaiveBayes

Same as =NaiveBayesContextRestricted=, but aware of options.

|Vote agreement threshold|Classifier trained on *EMEA*|Classifier trained on *Medline*|Window size|
|60%|53.2%||2|
|60%|54.8%||3|
|75%|59.2%|63.3%|3|
|75%|51.0%|48.9%|2|

** OptionAwareNaiveBayesLeftRight

Same as =OptionAwareNaiveBayes= but with different left and right contexts.

|Vote agreement threshold|Classifier trained on *EMEA*|Classifier trained on *Medline*|Window size|
|75%|53.1%|51.0%|2|
|75%|67.3%|55.1%|3|
|75%|51.0%|65.3%|10|

** OptionAwareNaiveBayesBigrams

Switched from just bigrams to unigrams and bigrams. 

|Vote agreement threshold|Classifier trained on *EMEA*|Classifier trained on *Medline*|Window size|
|75%|51.0%|59.2%|16|
|75%|51.0%|59.2%|10|
|75%|46.9%|59.2%|4|

** OptionAwareNaiveBayesFullContextLeftRight

|Vote agreement threshold|Classifier trained on *EMEA*|Classifier trained on *Medline*|
|75%|61.2%|67.3%|

** Best classifier

=OptionAwareNaiveBayesLeftRight= looks like the best classifier, with window size =3= for EMEA and unrestricted context (or big window sizes) for Medline.

* Dimensionality reduction

Two dimensionality reduction strategies have been investigated for the currently used bag of words:

1. Removing words with low frequencies from the bag of words dictionary - =ContextRestrictedBagOfWordsLeftRightCutoff=
1. Removing English stop-words (from =sklearn= stop-word list) - =ContextRestrictedBagOfWordsLeftRightStopWords=

Full experiment results *for vote agreement threshold 75%* can be observerd [[compare_vectorizers.tsv][here]]. Summary:

1. As suspected, deleting stop-words makes classification worse
1. Cut-off works well for Medline

Best results for either EMEA or Medline:

|Classifier|Window size|Word frequency cut-off|Agreement when trained on EMEA|Agreement when trained on Medline|
|OptionAwareNaiveBayesLeftRightCutoff|8|9|53.1%|73.5%|
|OptionAwareNaiveBayesLeftRightCutoff|4|2|67.3%|55.1%|
|OptionAwareNaiveBayesLeftRight|4||67.3%|53.1%|
|OptionAwareNaiveBayesFullContextLeftRightCutoff||8|61.2%|75.5%|

The Medline results are the same as =OptionAwareNaiveBayesFullContext= without cut-off, so this classifier needs to be tested with cut-off as well for Medline.

[[http://davtyan.org/pml/feature-chart.png]]

*** Re-evaluation

Results have been evaluated on a new dataset and changed significantly, see [[compare_vectorizers.tsv][here]]. The best classifier now is

|Classifier|Window size|Word frequency cut-off|Agreement when trained on EMEA|Agreement when trained on Medline|
|OptionAwareNaiveBayesLeftRightCutoff|5|9|58.3%|67.0%|

* Self-contained MTurk classification

Experiment: train =OptionAwareNaiveBayesLeftRight= classifier purely on MTurk labeled data and perform leave-one-out cross-validation.

|Vote agreement threshold|CV score|Window size|
|75%|49.5%|1|
|75%|49.5%|3|
|75%|49.5%|10|

The features are actually different for each window size but doesn't seem to affect the results. Same for using different priors. Hence, MTurk data is not enough to train the classifier, need to use unombiguous data as well.

* Agreement MTurk vs. Expert

About 200 instances were hand-annotated by an expert and compared with MTurk votes. The comparison table can be downloaded [[http://davtyan.org/pml/mturk_expert_comparison.xlsx][here]]. In the table, result =NONE= for Mechanical Turk means eigher =None of the above= or =I don't know= replies.

|Cases|Agreement|
|All cases|61%|
|Where MTurk majority vote is meaningful|76%|
|Where both votes are meaningful|81%|

By meaningful vote here we mean not =None of the above= and not =I don't know=.

* Agreement Classifier vs. Expert

About 200 instances were hand-annotated by an expert and compared with classifier votes. 

|Classifier | Strict Agreement| Meaningful Agreement |
|WeightedPartialFitPassiveTransferClassifier_Medline_2| 53%| 61.3%|

By meaningful agreement here we mean we exclude the points where experts says =IDK= or =None=.


* Transfer learning and Active learning

See results in the [[transfer_active.md][separate file]]
